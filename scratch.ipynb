{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cfe58dc-d72a-47e3-bf23-db6fd9361fb0",
   "metadata": {},
   "source": [
    "Importing necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "039e26b1-ea60-4825-885e-03818d10146a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a2fda-78f4-4847-af23-4ebbd24e22e0",
   "metadata": {},
   "source": [
    "Loading and viewing the dataset. This dataset contains 39717 rows and 111 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc6d167-f37c-4a74-84f7-ce4a43ff2bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\odil\\AppData\\Local\\Temp\\ipykernel_9720\\3878986248.py:1: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/loan.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/loan.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc4afdf-8462-4106-9b46-c73e128765bc",
   "metadata": {},
   "source": [
    "Cleaning the dataframe by dropping the columns that only have null values. Only 57 columns remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a047780e-485e-4fc7-ab76-4a315e67ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ced6bc-6b8d-4891-8509-c5a45c6d3eeb",
   "metadata": {},
   "source": [
    "Checking the null count for the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84cf7a7c-a20f-49de-b46c-bdf3dae3e093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                0\n",
       "member_id                         0\n",
       "loan_amnt                         0\n",
       "funded_amnt                       0\n",
       "funded_amnt_inv                   0\n",
       "term                              0\n",
       "int_rate                          0\n",
       "installment                       0\n",
       "grade                             0\n",
       "sub_grade                         0\n",
       "emp_title                      2459\n",
       "emp_length                     1075\n",
       "home_ownership                    0\n",
       "annual_inc                        0\n",
       "verification_status               0\n",
       "issue_d                           0\n",
       "loan_status                       0\n",
       "pymnt_plan                        0\n",
       "url                               0\n",
       "desc                          12942\n",
       "purpose                           0\n",
       "title                            11\n",
       "zip_code                          0\n",
       "addr_state                        0\n",
       "dti                               0\n",
       "delinq_2yrs                       0\n",
       "earliest_cr_line                  0\n",
       "inq_last_6mths                    0\n",
       "mths_since_last_delinq        25682\n",
       "mths_since_last_record        36931\n",
       "open_acc                          0\n",
       "pub_rec                           0\n",
       "revol_bal                         0\n",
       "revol_util                       50\n",
       "total_acc                         0\n",
       "initial_list_status               0\n",
       "out_prncp                         0\n",
       "out_prncp_inv                     0\n",
       "total_pymnt                       0\n",
       "total_pymnt_inv                   0\n",
       "total_rec_prncp                   0\n",
       "total_rec_int                     0\n",
       "total_rec_late_fee                0\n",
       "recoveries                        0\n",
       "collection_recovery_fee           0\n",
       "last_pymnt_d                     71\n",
       "last_pymnt_amnt                   0\n",
       "next_pymnt_d                  38577\n",
       "last_credit_pull_d                2\n",
       "collections_12_mths_ex_med       56\n",
       "policy_code                       0\n",
       "application_type                  0\n",
       "acc_now_delinq                    0\n",
       "chargeoff_within_12_mths         56\n",
       "delinq_amnt                       0\n",
       "pub_rec_bankruptcies            697\n",
       "tax_liens                        39\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189515d3-422b-42ca-8c1e-d4e694cdef2b",
   "metadata": {},
   "source": [
    "Dropping the columns where the majority of rows are null. For example, the column `mths_since_last_delinq` has 25682 rows with null values out of the total 39717 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e01f1da-964e-4c00-887e-60776ee551a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping these columns either because majority of their rows are null\n",
    "df.drop(columns=['mths_since_last_record', \n",
    "                 'next_pymnt_d', \n",
    "                 'mths_since_last_delinq'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa1779f-28e9-490e-a799-948b5794815b",
   "metadata": {},
   "source": [
    "Checking the number of unique values for the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2f3a05f-8433-4591-a308-2da81d965a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                            39717\n",
       "member_id                     39717\n",
       "loan_amnt                       885\n",
       "funded_amnt                    1041\n",
       "funded_amnt_inv                8205\n",
       "term                              2\n",
       "int_rate                        371\n",
       "installment                   15383\n",
       "grade                             7\n",
       "sub_grade                        35\n",
       "emp_title                     28820\n",
       "emp_length                       11\n",
       "home_ownership                    5\n",
       "annual_inc                     5318\n",
       "verification_status               3\n",
       "issue_d                          55\n",
       "loan_status                       3\n",
       "pymnt_plan                        1\n",
       "url                           39717\n",
       "desc                          26526\n",
       "purpose                          14\n",
       "title                         19615\n",
       "zip_code                        823\n",
       "addr_state                       50\n",
       "dti                            2868\n",
       "delinq_2yrs                      11\n",
       "earliest_cr_line                526\n",
       "inq_last_6mths                    9\n",
       "mths_since_last_delinq           95\n",
       "mths_since_last_record          111\n",
       "open_acc                         40\n",
       "pub_rec                           5\n",
       "revol_bal                     21711\n",
       "revol_util                     1089\n",
       "total_acc                        82\n",
       "initial_list_status               1\n",
       "out_prncp                      1137\n",
       "out_prncp_inv                  1138\n",
       "total_pymnt                   37850\n",
       "total_pymnt_inv               37518\n",
       "total_rec_prncp                7976\n",
       "total_rec_int                 35148\n",
       "total_rec_late_fee             1356\n",
       "recoveries                     4040\n",
       "collection_recovery_fee        2616\n",
       "last_pymnt_d                    101\n",
       "last_pymnt_amnt               34930\n",
       "next_pymnt_d                      2\n",
       "last_credit_pull_d              106\n",
       "collections_12_mths_ex_med        1\n",
       "policy_code                       1\n",
       "application_type                  1\n",
       "acc_now_delinq                    1\n",
       "chargeoff_within_12_mths          1\n",
       "delinq_amnt                       1\n",
       "pub_rec_bankruptcies              3\n",
       "tax_liens                         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_counts = df.nunique()\n",
    "unique_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4027421-08e1-4a43-9074-03539ee17ff5",
   "metadata": {},
   "source": [
    "Dropping the columns where the value in each row is unique. We also drop the columns that have the same value across all rows. Both cases do not display any pattern that can help predict the credit score of the individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2fa4c23-e917-4442-8531-41cdfc49759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = unique_counts[(unique_counts == df.shape[0]) | (unique_counts == 1)].index\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c277f90-f47c-4c2d-956d-d8c2f8eea4d8",
   "metadata": {},
   "source": [
    "Our target feature in this dataset is `grade`. This represents the credit score of the individual. We will convert this feature to numeric format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "264a422f-3ffb-4107-8f8b-6543631b273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['grade'] = label_encoder.fit_transform(df['grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "323607fa-6be3-449e-9e3d-48d2414c3502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering these columns to make them numeric\n",
    "df['int_rate_'] = df['int_rate'].str.replace('%', '').astype(float)\n",
    "df['emp_length_'] = df.emp_length.str[:2].str.strip().replace('<', '0').astype(float)\n",
    "df['revol_util_'] = df.revol_util.str[:-1].astype(float)\n",
    "\n",
    "# to convert dates to numeric format, the difference between the earliest date and current date is found\n",
    "# changing the date columns' data types to datetime\n",
    "for date_col in ['earliest_cr_line', 'issue_d', 'last_pymnt_d', 'last_credit_pull_d']:\n",
    "    df[date_col] = pd.to_datetime(df[date_col], format='%b-%y')\n",
    "\n",
    "# `earliest_cr_line` feature is calculated separately because its earliest date is 1969\n",
    "elapsed_months = (df['earliest_cr_line'].dt.year - df['earliest_cr_line'].min().year) * 12 + (df['earliest_cr_line'].dt.month - df['earliest_cr_line'].min().month)\n",
    "df['earliest_cr_line'] = elapsed_months\n",
    "\n",
    "# calculating for other date features | January 2007 was selected because the dataset is b/w 2007-2011\n",
    "earliest_ref_d = pd.to_datetime('2007-01-01')\n",
    "\n",
    "for date_col in ['issue_d', 'last_pymnt_d', 'last_credit_pull_d']:\n",
    "    elapsed_months = (df[date_col].dt.year - earliest_ref_d.year) * 12 + (df[date_col].dt.month - earliest_ref_d.month)\n",
    "    df[date_col] = elapsed_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d82d4571-226e-4d1e-b6b8-74d2c0e48a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these columns are one-hot encoded\n",
    "df['term_'] = df['term'].map({' 36 months': 0, ' 60 months': 1})\n",
    "df = pd.get_dummies(df, columns=['home_ownership'])\n",
    "\n",
    "# converting the dummy boolean columns to 0 and 1s\n",
    "boolean_cols = df.select_dtypes(include='bool').columns\n",
    "df[boolean_cols] = df[boolean_cols].astype(int)\n",
    "\n",
    "# target encoding these columns due to high cardinality (too many categories)\n",
    "for col in ['purpose', 'zip_code', 'addr_state']:\n",
    "    df[col] = df[col].map(df.groupby(col)['grade'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a371cfc7-08e0-4c0e-ac8a-539ce78fc85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these columns are ordinally encoded due to their inherent order\n",
    "df['loan_status_'] = df['loan_status'].map({'Charged Off': 0,\n",
    "                                            'Current': 1,\n",
    "                                            'Fully Paid': 2})\n",
    "df['verification_status_'] = df['verification_status'].map({'Not Verified': 0,\n",
    "                                                            'Verified': 1,\n",
    "                                                            'Source Verified': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66812e0a-295b-480a-8dce-b8a349a3f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the old columns after the above changes\n",
    "df.drop(columns=['term',\n",
    "                 'int_rate',\n",
    "                 'loan_status',\n",
    "                 'emp_length',\n",
    "                 'verification_status',\n",
    "                 'revol_util',\n",
    "                 'home_ownership_NONE',  # mostly 0 values\n",
    "                 'out_prncp',  # ditto\n",
    "                 'home_ownership_OTHER',  # ditto\n",
    "                 'desc',  # irrelevant\n",
    "                 'earliest_cr_line', # ditto\n",
    "                 'title',  # ditto\n",
    "                 'emp_title',  # too many categories (28820)\n",
    "                 'sub_grade',  # an extension of the target feature\n",
    "                ], inplace=True)\n",
    "\n",
    "# removing columns that end with `_inv` as they are almost duplicates of other columns\n",
    "df.drop(columns=df.columns[df.columns.str[-4:] == '_inv'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7957f2e1-cce1-4376-8b22-eb894832de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization is unnecessary since tree-based algorithms can handle large differences in feature scales\n",
    "# some features still have missing values. however, xgboost can work around them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10df8b42-b55f-4122-8075-23888e9181b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into sets 60-20-20\n",
    "X = df.drop('grade', axis=1)\n",
    "y = df['grade']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f97e8ef6-5f8e-4109-9f3d-2e19490091b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGBClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[0;32m      2\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti:softmax\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m     use_label_encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'XGBClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    n_estimators=100,\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c848ba-488c-4a2f-853a-aa3ff64a89ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46beb53a-ca11-4e50-972c-29746bc5c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation on test set\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy on test set:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485e2ae-5b14-4070-8409-b5ce3d72ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "\n",
    "# rejoin train and val sets since cross validation is used\n",
    "X_train = pd.concat([X_train, X_val], ignore_index=True)\n",
    "y_train = pd.concat([y_train, y_val], ignore_index=True)\n",
    "\n",
    "model = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth': randint(3, 10),\n",
    "    'min_child_weight': randint(1, 6),\n",
    "    'gamma': uniform(0, 0.5),\n",
    "    'subsample': uniform(0.6, 0.9),\n",
    "    'colsample_bytree': uniform(0.6, 0.9),\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'n_estimators': randint(100, 500)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faed22aa-aba5-455a-bd29-009012bb9484",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = random_search.best_params_\n",
    "\n",
    "print(f'Best parameters: {best_params}')\n",
    "print(f'Best score: {random_search.best_score_}')\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(\"Accuracy on test set:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79156cbe-a240-465f-90ba-0e0b10250e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    **best_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c8c008-a934-41fb-ad53-f386e783b17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f137d-1ab2-4f22-acb8-3bebe5d0ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Accuracy on test set:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f461fc34-4da2-4aee-b16d-1ef2eb363997",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save_model('best_xgboost_model.json')\n",
    "\n",
    "# loading the model\n",
    "# xgb.Booster().load_model('my_xgboost_model.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
